{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "LnAEaWf7VSnm",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-22 21:47:35.345102: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-22 21:47:36.336113: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2023-05-22 21:47:36.336244: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2023-05-22 21:47:36.336255: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "!pip3 install -qq -U wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "LnAEaWf7VSnm",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-24 13:11:16.604926: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-24 13:11:17.620743: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2023-05-24 13:11:17.620875: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2023-05-24 13:11:17.620886: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import tensorflow.compat.v2 as tf\n",
    "from tensorflow import keras as k\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.datasets import cifar10\n",
    "from keras import backend\n",
    "from keras.engine import base_layer\n",
    "from keras.engine import base_preprocessing_layer\n",
    "from keras.engine import input_spec\n",
    "from keras.layers.preprocessing import preprocessing_utils as utils\n",
    "from keras.utils import image_utils\n",
    "from keras.utils import conv_utils\n",
    "from matplotlib import pyplot\n",
    "from tqdm.keras import TqdmCallback\n",
    "import wandb\n",
    "from wandb.keras import WandbMetricsLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "x6tVYzzlUyZc"
   },
   "outputs": [],
   "source": [
    "# load train and test dataset\n",
    "def load_dataset():\n",
    "    # load dataset\n",
    "    (trainX, trainY), (testX, testY) = cifar10.load_data()\n",
    "    # one hot encode target values\n",
    "    trainY = k.utils.to_categorical(trainY)\n",
    "    testY = k.utils.to_categorical(testY)\n",
    "    return trainX, trainY, testX, testY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "KRxPb-9AVpyx"
   },
   "outputs": [],
   "source": [
    "# scale pixels\n",
    "def prep_pixels(train, test):\n",
    "    # convert from integers to floats\n",
    "    train_norm = train.astype('float32')\n",
    "    test_norm = test.astype('float32')\n",
    "    # normalize to range 0-1\n",
    "    train_norm = train_norm / 255.0\n",
    "    test_norm = test_norm / 255.0\n",
    "    # return normalized images\n",
    "    return train_norm, test_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "9w5nuIScHCh3"
   },
   "outputs": [],
   "source": [
    "# scale pixel : normalize and center pixel\n",
    "def prep_pixels_mean_std(train, test):\n",
    " # convert from integers to floats\n",
    " train_norm = train.astype('float32')\n",
    " test_norm = test.astype('float32')\n",
    " # normalize to range 0-1\n",
    " train_norm = (train_norm - train_norm.mean())/train_norm.std()\n",
    " test_norm = (test_norm - test_norm.mean())/test_norm.std()\n",
    " # return normalized images\n",
    " return train_norm, test_norm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "ek08tshyAyrw"
   },
   "source": [
    "# Nouvelle section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "yvYUB6ynXS1j"
   },
   "outputs": [],
   "source": [
    "def summarize_diagnostics(history):\n",
    "    min_loss = min(history.history['val_loss'])\n",
    "    print(f'Minimum validation loss {min_loss} at epoch {history.history[\"val_loss\"].index(min_loss)}')\n",
    "    best_acc = max(history.history['val_accuracy'])\n",
    "    print(f'Best validation accuracy {best_acc} at epoch {history.history[\"val_accuracy\"].index(best_acc)}')\n",
    "    # plot loss\n",
    "    pyplot.subplot(211)\n",
    "    pyplot.title('Cross Entropy Loss')\n",
    "    pyplot.plot(history.history['loss'], color='blue', label='train')\n",
    "    pyplot.plot(history.history['val_loss'], color='orange', label='test')\n",
    "    # plot accuracy\n",
    "    pyplot.subplot(212)\n",
    "    pyplot.title('Classification Accuracy')\n",
    "    pyplot.plot(history.history['accuracy'], color='blue', label='train')\n",
    "    pyplot.plot(history.history['val_accuracy'], color='orange', label='test')\n",
    "    # save plot to file\n",
    "    filename = sys.argv[0].split('/')[-1]\n",
    "    pyplot.tight_layout()\n",
    "    pyplot.savefig(filename + '_plot.png')\n",
    "    pyplot.close()\n",
    "    with open('stats.txt', 'w') as f:\n",
    "        f.write(f'{min_loss} @ {history.history[\"val_loss\"].index(min_loss)}\\n{best_acc} @ {history.history[\"val_accuracy\"].index(best_acc)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "H_AXIS = -3\n",
    "W_AXIS = -2\n",
    "\n",
    "\n",
    "def convert_inputs(inputs, dtype=None):\n",
    "    if isinstance(inputs, dict):\n",
    "        raise ValueError(\n",
    "            \"This layer can only process a tensor representing an image or \"\n",
    "            f\"a batch of images. Received: type(inputs)={type(inputs)}.\"\n",
    "            \"If you need to pass a dict containing \"\n",
    "            \"images, labels, and bounding boxes, you should \"\n",
    "            \"instead use the preprocessing and augmentation layers \"\n",
    "            \"from `keras_cv.layers`. See docs at \"\n",
    "            \"https://keras.io/api/keras_cv/layers/\"\n",
    "        )\n",
    "    inputs = utils.ensure_tensor(inputs, dtype=dtype)\n",
    "    return inputs\n",
    "\n",
    "\n",
    "class RandomCrop(base_layer.BaseRandomLayer):\n",
    "\n",
    "    def __init__(self, height, width, seed=None, **kwargs):\n",
    "        base_preprocessing_layer.keras_kpl_gauge.get_cell(\"RandomCrop\").set(\n",
    "            True\n",
    "        )\n",
    "        super().__init__(\n",
    "            **kwargs, autocast=False, seed=seed, force_generator=True\n",
    "        )\n",
    "        self.height = height\n",
    "        self.width = width\n",
    "        self.seed = seed\n",
    "\n",
    "    def call(self, inputs, training=True):\n",
    "        inputs = convert_inputs(inputs, dtype=self.compute_dtype)\n",
    "        input_shape = tf.shape(inputs)\n",
    "        h_diff = input_shape[H_AXIS] - self.height\n",
    "        w_diff = input_shape[W_AXIS] - self.width\n",
    "\n",
    "        def random_crop():\n",
    "            dtype = input_shape.dtype\n",
    "            rands = self._random_generator.random_uniform(\n",
    "                [2], 0, dtype.max, dtype\n",
    "            )\n",
    "            h_start = rands[0] % (h_diff + 1)\n",
    "            w_start = rands[1] % (w_diff + 1)\n",
    "            return tf.image.crop_to_bounding_box(\n",
    "                inputs, h_start, w_start, self.height, self.width\n",
    "            )\n",
    "\n",
    "        def resize():\n",
    "            outputs = image_utils.smart_resize(\n",
    "                inputs, [self.height, self.width]\n",
    "            )\n",
    "            # smart_resize will always output float32, so we need to re-cast.\n",
    "            return tf.cast(outputs, self.compute_dtype)\n",
    "\n",
    "        return tf.cond(\n",
    "            tf.reduce_all((training, h_diff >= 0, w_diff >= 0)),\n",
    "            random_crop,\n",
    "            resize,\n",
    "        )\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        input_shape = tf.TensorShape(input_shape).as_list()\n",
    "        input_shape[H_AXIS] = self.height\n",
    "        input_shape[W_AXIS] = self.width\n",
    "        return tf.TensorShape(input_shape)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\n",
    "            \"height\": self.height,\n",
    "            \"width\": self.width,\n",
    "            \"seed\": self.seed,\n",
    "        }\n",
    "        base_config = super().get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ZeroPadding2D(base_layer.Layer):\n",
    "\n",
    "    def __init__(self, padding=(1, 1), data_format=None, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.data_format = conv_utils.normalize_data_format(data_format)\n",
    "        if isinstance(padding, int):\n",
    "            self.padding = ((padding, padding), (padding, padding))\n",
    "        elif hasattr(padding, \"__len__\"):\n",
    "            if len(padding) != 2:\n",
    "                raise ValueError(\n",
    "                    f\"`padding` should have two elements. Received: {padding}.\"\n",
    "                )\n",
    "            height_padding = conv_utils.normalize_tuple(\n",
    "                padding[0], 2, \"1st entry of padding\", allow_zero=True\n",
    "            )\n",
    "            width_padding = conv_utils.normalize_tuple(\n",
    "                padding[1], 2, \"2nd entry of padding\", allow_zero=True\n",
    "            )\n",
    "            self.padding = (height_padding, width_padding)\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                \"`padding` should be either an int, \"\n",
    "                \"a tuple of 2 ints \"\n",
    "                \"(symmetric_height_pad, symmetric_width_pad), \"\n",
    "                \"or a tuple of 2 tuples of 2 ints \"\n",
    "                \"((top_pad, bottom_pad), (left_pad, right_pad)). \"\n",
    "                f\"Received: {padding}.\"\n",
    "            )\n",
    "        self.input_spec = input_spec.InputSpec(ndim=4)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        input_shape = tf.TensorShape(input_shape).as_list()\n",
    "        if self.data_format == \"channels_first\":\n",
    "            if input_shape[2] is not None:\n",
    "                rows = input_shape[2] + self.padding[0][0] + self.padding[0][1]\n",
    "            else:\n",
    "                rows = None\n",
    "            if input_shape[3] is not None:\n",
    "                cols = input_shape[3] + self.padding[1][0] + self.padding[1][1]\n",
    "            else:\n",
    "                cols = None\n",
    "            return tf.TensorShape([input_shape[0], input_shape[1], rows, cols])\n",
    "        elif self.data_format == \"channels_last\":\n",
    "            if input_shape[1] is not None:\n",
    "                rows = input_shape[1] + self.padding[0][0] + self.padding[0][1]\n",
    "            else:\n",
    "                rows = None\n",
    "            if input_shape[2] is not None:\n",
    "                cols = input_shape[2] + self.padding[1][0] + self.padding[1][1]\n",
    "            else:\n",
    "                cols = None\n",
    "            return tf.TensorShape([input_shape[0], rows, cols, input_shape[3]])\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        if training:\n",
    "            return backend.spatial_2d_padding(\n",
    "                inputs, padding=self.padding, data_format=self.data_format\n",
    "            )\n",
    "        return inputs\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\"padding\": self.padding, \"data_format\": self.data_format}\n",
    "        base_config = super().get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_resnet(wdecay=0):\n",
    "    inputs = k.Input(shape=(32, 32, 3))\n",
    "    \n",
    "    #DATA AUGMENTATION (inactive during inference)\n",
    "    aug = ZeroPadding2D(4)(inputs)\n",
    "    aug = k.layers.RandomFlip(mode='horizontal')(aug)\n",
    "    aug = RandomCrop(32, 32)(aug)\n",
    "    \n",
    "    #layer1 = k.layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_uniform',\n",
    "    #    kernel_regularizer=k.regularizers.l2(wdecay), padding='same')(aug)\n",
    "    layer1 = k.layers.Conv2D(16, (3, 3), kernel_initializer='he_uniform',\n",
    "        kernel_regularizer=k.regularizers.l2(wdecay), padding='same')(aug)\n",
    "    layer1 = k.layers.BatchNormalization()(layer1)\n",
    "    layer1 = k.layers.Activation(k.activations.relu)(layer1)\n",
    "    #FIRST STACK\n",
    "    #x = k.layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_uniform',\n",
    "    #    kernel_regularizer=k.regularizers.l2(wdecay), padding='same')(layer1)\n",
    "    x = k.layers.Conv2D(16, (3, 3), kernel_initializer='he_uniform',\n",
    "        kernel_regularizer=k.regularizers.l2(wdecay), padding='same')(layer1)\n",
    "    x = k.layers.BatchNormalization()(x)\n",
    "    x = k.layers.Activation(k.activations.relu)(x)\n",
    "    #x = k.layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_uniform',\n",
    "    #    kernel_regularizer=k.regularizers.l2(wdecay), padding='same')(x)\n",
    "    x = k.layers.Conv2D(16, (3, 3), kernel_initializer='he_uniform',\n",
    "        kernel_regularizer=k.regularizers.l2(wdecay), padding='same')(x)\n",
    "    x = k.layers.BatchNormalization()(x)\n",
    "    #x = k.layers.Activation(k.activations.relu)(x)\n",
    "    res = k.layers.Activation(k.activations.relu)(k.layers.Add()([layer1, x]))\n",
    "    #x = k.layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_uniform',\n",
    "    #    kernel_regularizer=k.regularizers.l2(wdecay), padding='same')(res)\n",
    "    x = k.layers.Conv2D(16, (3, 3), kernel_initializer='he_uniform',\n",
    "        kernel_regularizer=k.regularizers.l2(wdecay), padding='same')(res)\n",
    "    x = k.layers.BatchNormalization()(x)\n",
    "    x = k.layers.Activation(k.activations.relu)(x)\n",
    "    #x = k.layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_uniform',\n",
    "    #    kernel_regularizer=k.regularizers.l2(wdecay), padding='same')(x)\n",
    "    x = k.layers.Conv2D(16, (3, 3), kernel_initializer='he_uniform',\n",
    "        kernel_regularizer=k.regularizers.l2(wdecay), padding='same')(x)\n",
    "    x = k.layers.BatchNormalization()(x)\n",
    "    #x = k.layers.Activation(k.activations.relu)(x)\n",
    "    res = k.layers.Activation(k.activations.relu)(k.layers.Add()([res, x]))\n",
    "    #x = k.layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_uniform',\n",
    "    #    kernel_regularizer=k.regularizers.l2(wdecay), padding='same')(res)\n",
    "    x = k.layers.Conv2D(16, (3, 3), kernel_initializer='he_uniform',\n",
    "        kernel_regularizer=k.regularizers.l2(wdecay), padding='same')(res)\n",
    "    x = k.layers.BatchNormalization()(x)\n",
    "    x = k.layers.Activation(k.activations.relu)(x)\n",
    "    #x = k.layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_uniform',\n",
    "    #    kernel_regularizer=k.regularizers.l2(wdecay), padding='same')(x)\n",
    "    x = k.layers.Conv2D(16, (3, 3), kernel_initializer='he_uniform',\n",
    "        kernel_regularizer=k.regularizers.l2(wdecay), padding='same')(x)\n",
    "    x = k.layers.BatchNormalization()(x)\n",
    "    #x = k.layers.Activation(k.activations.relu)(x)\n",
    "    res = k.layers.Activation(k.activations.relu)(k.layers.Add()([res, x]))\n",
    "    \n",
    "    #SECOND STACK\n",
    "    #x = k.layers.Conv2D(32, (3, 3), strides=(2, 2), activation='relu', kernel_initializer='he_uniform',\n",
    "    #    kernel_regularizer=k.regularizers.l2(wdecay), padding='same')(res)\n",
    "    x = k.layers.Conv2D(32, (3, 3), strides=(2, 2), kernel_initializer='he_uniform',\n",
    "        kernel_regularizer=k.regularizers.l2(wdecay), padding='same')(res)\n",
    "    x = k.layers.BatchNormalization()(x)\n",
    "    x = k.layers.Activation(k.activations.relu)(x)\n",
    "    x = k.layers.Conv2D(32, (3, 3), kernel_initializer='he_uniform',\n",
    "        kernel_regularizer=k.regularizers.l2(wdecay), padding='same')(x)\n",
    "    x = k.layers.BatchNormalization()(x)\n",
    "    #x = k.layers.Activation(k.activations.relu)(x)\n",
    "    res = k.layers.Conv2D(32, (1, 1), strides=(2, 2), kernel_initializer='he_uniform',\n",
    "        kernel_regularizer=k.regularizers.l2(wdecay), padding='same')(res)\n",
    "    res = k.layers.Activation(k.activations.relu)(k.layers.Add()([res, x]))\n",
    "    #x = k.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform',\n",
    "    #    kernel_regularizer=k.regularizers.l2(wdecay), padding='same')(res)\n",
    "    x = k.layers.Conv2D(32, (3, 3), kernel_initializer='he_uniform',\n",
    "        kernel_regularizer=k.regularizers.l2(wdecay), padding='same')(res)\n",
    "    x = k.layers.BatchNormalization()(x)\n",
    "    x = k.layers.Activation(k.activations.relu)(x)\n",
    "    #x = k.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform',\n",
    "    #    kernel_regularizer=k.regularizers.l2(wdecay), padding='same')(x)\n",
    "    x = k.layers.Conv2D(32, (3, 3), kernel_initializer='he_uniform',\n",
    "        kernel_regularizer=k.regularizers.l2(wdecay), padding='same')(x)\n",
    "    x = k.layers.BatchNormalization()(x)\n",
    "    #x = k.layers.Activation(k.activations.relu)(x)\n",
    "    res = k.layers.Activation(k.activations.relu)(k.layers.Add()([res, x]))\n",
    "    #x = k.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform',\n",
    "    #    kernel_regularizer=k.regularizers.l2(wdecay), padding='same')(res)\n",
    "    x = k.layers.Conv2D(32, (3, 3), kernel_initializer='he_uniform',\n",
    "        kernel_regularizer=k.regularizers.l2(wdecay), padding='same')(res)\n",
    "    x = k.layers.BatchNormalization()(x)\n",
    "    x = k.layers.Activation(k.activations.relu)(x)\n",
    "    #x = k.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform',\n",
    "    #    kernel_regularizer=k.regularizers.l2(wdecay), padding='same')(x)\n",
    "    x = k.layers.Conv2D(32, (3, 3), kernel_initializer='he_uniform',\n",
    "        kernel_regularizer=k.regularizers.l2(wdecay), padding='same')(x)\n",
    "    x = k.layers.BatchNormalization()(x)\n",
    "    #x = k.layers.Activation(k.activations.relu)(x)\n",
    "    res = k.layers.Activation(k.activations.relu)(k.layers.Add()([res, x]))\n",
    "    \n",
    "    #THIRD STACK\n",
    "    #x = k.layers.Conv2D(64, (3, 3), strides=(2, 2), activation='relu', kernel_initializer='he_uniform',\n",
    "    #    kernel_regularizer=k.regularizers.l2(wdecay), padding='same')(res)\n",
    "    x = k.layers.Conv2D(64, (3, 3), strides=(2, 2), kernel_initializer='he_uniform',\n",
    "        kernel_regularizer=k.regularizers.l2(wdecay), padding='same')(res)\n",
    "    x = k.layers.BatchNormalization()(x)\n",
    "    x = k.layers.Activation(k.activations.relu)(x)\n",
    "    #x = k.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform',\n",
    "    #    kernel_regularizer=k.regularizers.l2(wdecay), padding='same')(x)\n",
    "    x = k.layers.Conv2D(64, (3, 3), kernel_initializer='he_uniform',\n",
    "        kernel_regularizer=k.regularizers.l2(wdecay), padding='same')(x)\n",
    "    x = k.layers.BatchNormalization()(x)\n",
    "    #x = k.layers.Activation(k.activations.relu)(x)\n",
    "    res = k.layers.Conv2D(64, (1, 1), strides=(2, 2), kernel_initializer='he_uniform',\n",
    "        kernel_regularizer=k.regularizers.l2(wdecay), padding='same')(res)\n",
    "    res = k.layers.Activation(k.activations.relu)(k.layers.Add()([res, x]))\n",
    "    #x = k.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform',\n",
    "    #    kernel_regularizer=k.regularizers.l2(wdecay), padding='same')(res)\n",
    "    x = k.layers.Conv2D(64, (3, 3), kernel_initializer='he_uniform',\n",
    "        kernel_regularizer=k.regularizers.l2(wdecay), padding='same')(res)\n",
    "    x = k.layers.BatchNormalization()(x)\n",
    "    x = k.layers.Activation(k.activations.relu)(x)\n",
    "    #x = k.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform',\n",
    "    #    kernel_regularizer=k.regularizers.l2(wdecay), padding='same')(x)\n",
    "    x = k.layers.Conv2D(64, (3, 3), kernel_initializer='he_uniform',\n",
    "        kernel_regularizer=k.regularizers.l2(wdecay), padding='same')(x)\n",
    "    x = k.layers.BatchNormalization()(x)\n",
    "    #x = k.layers.Activation(k.activations.relu)(x)\n",
    "    res = k.layers.Activation(k.activations.relu)(k.layers.Add()([res, x]))\n",
    "    #x = k.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform',\n",
    "    #    kernel_regularizer=k.regularizers.l2(wdecay), padding='same')(res)\n",
    "    x = k.layers.Conv2D(64, (3, 3), kernel_initializer='he_uniform',\n",
    "        kernel_regularizer=k.regularizers.l2(wdecay), padding='same')(res)\n",
    "    x = k.layers.BatchNormalization()(x)\n",
    "    x = k.layers.Activation(k.activations.relu)(x)\n",
    "    #x = k.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform',\n",
    "    #    kernel_regularizer=k.regularizers.l2(wdecay), padding='same')(x)\n",
    "    x = k.layers.Conv2D(64, (3, 3), kernel_initializer='he_uniform',\n",
    "        kernel_regularizer=k.regularizers.l2(wdecay), padding='same')(x)\n",
    "    x = k.layers.BatchNormalization()(x)\n",
    "    #x = k.layers.Activation(k.activations.relu)(x)\n",
    "    res = k.layers.Activation(k.activations.relu)(k.layers.Add()([res, x]))\n",
    "    \n",
    "    res = k.layers.GlobalAveragePooling2D()(res)\n",
    "    \n",
    "    outputs = k.layers.Dense(10, activation='softmax')(res)\n",
    "    \n",
    "    return k.Model(inputs=inputs, outputs=outputs, name='ResNet_20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-24 13:11:46.109886: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-24 13:11:46.280110: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-24 13:11:46.280373: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-24 13:11:46.282674: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-24 13:11:46.284094: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-24 13:11:46.284330: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-24 13:11:46.284522: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-24 13:11:48.450353: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-24 13:11:48.464246: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-24 13:11:48.464523: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-24 13:11:48.471165: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15389 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.10/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n",
      "Model: \"ResNet_20\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 32, 32, 3)]  0           []                               \n",
      "                                                                                                  \n",
      " zero_padding2d (ZeroPadding2D)  (None, 32, 32, 3)   0           ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " random_flip (RandomFlip)       (None, 32, 32, 3)    0           ['zero_padding2d[0][0]']         \n",
      "                                                                                                  \n",
      " random_crop (RandomCrop)       (None, 32, 32, 3)    0           ['random_flip[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 32, 32, 16)   448         ['random_crop[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 32, 32, 16)  64          ['conv2d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 32, 32, 16)   0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 32, 32, 16)   2320        ['activation[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 32, 32, 16)  64          ['conv2d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 32, 32, 16)   0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 32, 32, 16)   2320        ['activation_1[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 32, 32, 16)  64          ['conv2d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 32, 32, 16)   0           ['activation[0][0]',             \n",
      "                                                                  'batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 32, 32, 16)   0           ['add[0][0]']                    \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 32, 32, 16)   2320        ['activation_2[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 32, 32, 16)  64          ['conv2d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 32, 32, 16)   0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 32, 32, 16)   2320        ['activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 32, 32, 16)  64          ['conv2d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 32, 32, 16)   0           ['activation_2[0][0]',           \n",
      "                                                                  'batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 32, 32, 16)   0           ['add_1[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 32, 32, 16)   2320        ['activation_4[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 32, 32, 16)  64          ['conv2d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 32, 32, 16)   0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 32, 32, 16)   2320        ['activation_5[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 32, 32, 16)  64          ['conv2d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, 32, 32, 16)   0           ['activation_4[0][0]',           \n",
      "                                                                  'batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 32, 32, 16)   0           ['add_2[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 16, 16, 32)   4640        ['activation_6[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 16, 16, 32)  128         ['conv2d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_7 (Activation)      (None, 16, 16, 32)   0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 16, 16, 32)   9248        ['activation_7[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 16, 16, 32)   544         ['activation_6[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 16, 16, 32)  128         ['conv2d_8[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " add_3 (Add)                    (None, 16, 16, 32)   0           ['conv2d_9[0][0]',               \n",
      "                                                                  'batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " activation_8 (Activation)      (None, 16, 16, 32)   0           ['add_3[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 16, 16, 32)   9248        ['activation_8[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 16, 16, 32)  128         ['conv2d_10[0][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_9 (Activation)      (None, 16, 16, 32)   0           ['batch_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 16, 16, 32)   9248        ['activation_9[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 16, 16, 32)  128         ['conv2d_11[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_4 (Add)                    (None, 16, 16, 32)   0           ['activation_8[0][0]',           \n",
      "                                                                  'batch_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " activation_10 (Activation)     (None, 16, 16, 32)   0           ['add_4[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 16, 16, 32)   9248        ['activation_10[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 16, 16, 32)  128         ['conv2d_12[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_11 (Activation)     (None, 16, 16, 32)   0           ['batch_normalization_11[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 16, 16, 32)   9248        ['activation_11[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 16, 16, 32)  128         ['conv2d_13[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_5 (Add)                    (None, 16, 16, 32)   0           ['activation_10[0][0]',          \n",
      "                                                                  'batch_normalization_12[0][0]'] \n",
      "                                                                                                  \n",
      " activation_12 (Activation)     (None, 16, 16, 32)   0           ['add_5[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 8, 8, 64)     18496       ['activation_12[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, 8, 8, 64)    256         ['conv2d_14[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_13 (Activation)     (None, 8, 8, 64)     0           ['batch_normalization_13[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, 8, 8, 64)     36928       ['activation_13[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)             (None, 8, 8, 64)     2112        ['activation_12[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_14 (BatchN  (None, 8, 8, 64)    256         ['conv2d_15[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_6 (Add)                    (None, 8, 8, 64)     0           ['conv2d_16[0][0]',              \n",
      "                                                                  'batch_normalization_14[0][0]'] \n",
      "                                                                                                  \n",
      " activation_14 (Activation)     (None, 8, 8, 64)     0           ['add_6[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)             (None, 8, 8, 64)     36928       ['activation_14[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_15 (BatchN  (None, 8, 8, 64)    256         ['conv2d_17[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_15 (Activation)     (None, 8, 8, 64)     0           ['batch_normalization_15[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)             (None, 8, 8, 64)     36928       ['activation_15[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_16 (BatchN  (None, 8, 8, 64)    256         ['conv2d_18[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_7 (Add)                    (None, 8, 8, 64)     0           ['activation_14[0][0]',          \n",
      "                                                                  'batch_normalization_16[0][0]'] \n",
      "                                                                                                  \n",
      " activation_16 (Activation)     (None, 8, 8, 64)     0           ['add_7[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_19 (Conv2D)             (None, 8, 8, 64)     36928       ['activation_16[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_17 (BatchN  (None, 8, 8, 64)    256         ['conv2d_19[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_17 (Activation)     (None, 8, 8, 64)     0           ['batch_normalization_17[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_20 (Conv2D)             (None, 8, 8, 64)     36928       ['activation_17[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_18 (BatchN  (None, 8, 8, 64)    256         ['conv2d_20[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_8 (Add)                    (None, 8, 8, 64)     0           ['activation_16[0][0]',          \n",
      "                                                                  'batch_normalization_18[0][0]'] \n",
      "                                                                                                  \n",
      " activation_18 (Activation)     (None, 8, 8, 64)     0           ['add_8[0][0]']                  \n",
      "                                                                                                  \n",
      " global_average_pooling2d (Glob  (None, 64)          0           ['activation_18[0][0]']          \n",
      " alAveragePooling2D)                                                                              \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 10)           650         ['global_average_pooling2d[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 274,442\n",
      "Trainable params: 273,066\n",
      "Non-trainable params: 1,376\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "resnet = define_resnet()\n",
    "resnet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_resnetplus(wdecay=0):\n",
    "    inputs = k.Input(shape=(32, 32, 3))\n",
    "    \n",
    "    #DATA AUGMENTATION (inactive during inference)\n",
    "    aug = ZeroPadding2D(4)(inputs)\n",
    "    #aug = k.layers.RandomFlip(mode='horizontal')(aug)\n",
    "    aug = RandomCrop(32, 32)(aug)\n",
    "    \n",
    "    layer1 = k.layers.Conv2D(16, (3, 3), kernel_initializer='he_uniform',\n",
    "        kernel_regularizer=k.regularizers.l2(wdecay), padding='same')(aug)\n",
    "    layer1 = k.layers.BatchNormalization()(layer1)\n",
    "    layer1 = k.layers.Activation(k.activations.relu)(layer1)\n",
    "    #FIRST STACK\n",
    "    x = k.layers.Conv2D(16, (3, 3), kernel_initializer='he_uniform',\n",
    "        kernel_regularizer=k.regularizers.l2(wdecay), padding='same')(layer1)\n",
    "    x = k.layers.BatchNormalization()(x)\n",
    "    x = k.layers.Activation(k.activations.relu)(x)\n",
    "    x = k.layers.Conv2D(16, (3, 3), kernel_initializer='he_uniform',\n",
    "        kernel_regularizer=k.regularizers.l2(wdecay), padding='same')(x)\n",
    "    x = k.layers.BatchNormalization()(x)\n",
    "    #x = k.layers.Activation(k.activations.relu)(x)\n",
    "    res = k.layers.Activation(k.activations.relu)(k.layers.Add()([layer1, x]))\n",
    "    x = k.layers.Conv2D(16, (3, 3), kernel_initializer='he_uniform',\n",
    "        kernel_regularizer=k.regularizers.l2(wdecay), padding='same')(res)\n",
    "    x = k.layers.BatchNormalization()(x)\n",
    "    x = k.layers.Activation(k.activations.relu)(x)\n",
    "    x = k.layers.Conv2D(16, (3, 3), kernel_initializer='he_uniform',\n",
    "        kernel_regularizer=k.regularizers.l2(wdecay), padding='same')(x)\n",
    "    x = k.layers.BatchNormalization()(x)\n",
    "    #x = k.layers.Activation(k.activations.relu)(x)\n",
    "    res = k.layers.Activation(k.activations.relu)(k.layers.Add()([res, x]))\n",
    "    x = k.layers.Conv2D(16, (3, 3), kernel_initializer='he_uniform',\n",
    "        kernel_regularizer=k.regularizers.l2(wdecay), padding='same')(res)\n",
    "    x = k.layers.BatchNormalization()(x)\n",
    "    x = k.layers.Activation(k.activations.relu)(x)\n",
    "    x = k.layers.Conv2D(16, (3, 3), kernel_initializer='he_uniform',\n",
    "        kernel_regularizer=k.regularizers.l2(wdecay), padding='same')(x)\n",
    "    x = k.layers.BatchNormalization()(x)\n",
    "    #x = k.layers.Activation(k.activations.relu)(x)\n",
    "    res = k.layers.Activation(k.activations.relu)(k.layers.Add()([res, x]))\n",
    "    \n",
    "    downres = k.layers.Conv2D(16, (1, 1), strides=(2, 2), activation='relu', kernel_initializer='he_uniform',\n",
    "        kernel_regularizer=k.regularizers.l2(wdecay), padding='same')(res)\n",
    "    \n",
    "    #SECOND STACK\n",
    "    x = k.layers.Conv2D(32, (3, 3), strides=(2, 2), kernel_initializer='he_uniform',\n",
    "        kernel_regularizer=k.regularizers.l2(wdecay), padding='same')(downres)\n",
    "    x = k.layers.BatchNormalization()(x)\n",
    "    x = k.layers.Activation(k.activations.relu)(x)\n",
    "    x = k.layers.Conv2D(32, (3, 3), kernel_initializer='he_uniform',\n",
    "        kernel_regularizer=k.regularizers.l2(wdecay), padding='same')(x)\n",
    "    x = k.layers.BatchNormalization()(x)\n",
    "    #x = k.layers.Activation(k.activations.relu)(x)\n",
    "    res = k.layers.Conv2D(32, (1, 1), strides=(2, 2), kernel_initializer='he_uniform',\n",
    "        kernel_regularizer=k.regularizers.l2(wdecay), padding='same')(res)\n",
    "    res = k.layers.Activation(k.activations.relu)(k.layers.Add()([res, x]))\n",
    "    x = k.layers.Conv2D(32, (3, 3), kernel_initializer='he_uniform',\n",
    "        kernel_regularizer=k.regularizers.l2(wdecay), padding='same')(res)\n",
    "    x = k.layers.BatchNormalization()(x)\n",
    "    x = k.layers.Activation(k.activations.relu)(x)\n",
    "    x = k.layers.Conv2D(32, (3, 3), kernel_initializer='he_uniform',\n",
    "        kernel_regularizer=k.regularizers.l2(wdecay), padding='same')(x)\n",
    "    x = k.layers.BatchNormalization()(x)\n",
    "    #x = k.layers.Activation(k.activations.relu)(x)\n",
    "    res = k.layers.Activation(k.activations.relu)(k.layers.Add()([res, x]))\n",
    "    x = k.layers.Conv2D(32, (3, 3), kernel_initializer='he_uniform',\n",
    "        kernel_regularizer=k.regularizers.l2(wdecay), padding='same')(res)\n",
    "    x = k.layers.BatchNormalization()(x)\n",
    "    x = k.layers.Activation(k.activations.relu)(x)\n",
    "    x = k.layers.Conv2D(32, (3, 3), kernel_initializer='he_uniform',\n",
    "        kernel_regularizer=k.regularizers.l2(wdecay), padding='same')(x)\n",
    "    x = k.layers.BatchNormalization()(x)\n",
    "    #x = k.layers.Activation(k.activations.relu)(x)\n",
    "    res = k.layers.Activation(k.activations.relu)(k.layers.Add()([res, x]))\n",
    "    \n",
    "    downres = k.layers.Conv2D(32, (1, 1), strides=(2, 2), activation='relu', kernel_initializer='he_uniform',\n",
    "        kernel_regularizer=k.regularizers.l2(wdecay), padding='same')(res)\n",
    "    \n",
    "    #THIRD STACK\n",
    "    x = k.layers.Conv2D(64, (3, 3), strides=(2, 2), kernel_initializer='he_uniform',\n",
    "        kernel_regularizer=k.regularizers.l2(wdecay), padding='same')(downres)\n",
    "    x = k.layers.BatchNormalization()(x)\n",
    "    x = k.layers.Activation(k.activations.relu)(x)\n",
    "    x = k.layers.Conv2D(64, (3, 3), kernel_initializer='he_uniform',\n",
    "        kernel_regularizer=k.regularizers.l2(wdecay), padding='same')(x)\n",
    "    x = k.layers.BatchNormalization()(x)\n",
    "    #x = k.layers.Activation(k.activations.relu)(x)\n",
    "    res = k.layers.Conv2D(64, (1, 1), strides=(2, 2), kernel_initializer='he_uniform',\n",
    "        kernel_regularizer=k.regularizers.l2(wdecay), padding='same')(res)\n",
    "    res = k.layers.Activation(k.activations.relu)(k.layers.Add()([res, x]))\n",
    "    x = k.layers.Conv2D(64, (3, 3), kernel_initializer='he_uniform',\n",
    "        kernel_regularizer=k.regularizers.l2(wdecay), padding='same')(res)\n",
    "    x = k.layers.BatchNormalization()(x)\n",
    "    x = k.layers.Activation(k.activations.relu)(x)\n",
    "    x = k.layers.Conv2D(64, (3, 3), kernel_initializer='he_uniform',\n",
    "        kernel_regularizer=k.regularizers.l2(wdecay), padding='same')(x)\n",
    "    x = k.layers.BatchNormalization()(x)\n",
    "    #x = k.layers.Activation(k.activations.relu)(x)\n",
    "    res = k.layers.Activation(k.activations.relu)(k.layers.Add()([res, x]))\n",
    "    x = k.layers.Conv2D(64, (3, 3), kernel_initializer='he_uniform',\n",
    "        kernel_regularizer=k.regularizers.l2(wdecay), padding='same')(res)\n",
    "    x = k.layers.BatchNormalization()(x)\n",
    "    x = k.layers.Activation(k.activations.relu)(x)\n",
    "    x = k.layers.Conv2D(64, (3, 3), kernel_initializer='he_uniform',\n",
    "        kernel_regularizer=k.regularizers.l2(wdecay), padding='same')(x)\n",
    "    x = k.layers.BatchNormalization()(x)\n",
    "    #x = k.layers.Activation(k.activations.relu)(x)\n",
    "    res = k.layers.Activation(k.activations.relu)(k.layers.Add()([res, x]))\n",
    "    \n",
    "    res = k.layers.GlobalAveragePooling2D()(res)\n",
    "    \n",
    "    outputs = k.layers.Dense(10, activation='softmax')(res)\n",
    "    \n",
    "    return k.Model(inputs=inputs, outputs=outputs, name='ResNet_20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#resnetplus = define_resnetplus()\n",
    "#resnetplus.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_resnext(wdecay=0):\n",
    "    inputs = k.Input(shape=(32, 32, 3))\n",
    "    \n",
    "    #DATA AUGMENTATION (inactive during inference)\n",
    "    aug = ZeroPadding2D(4)(inputs)\n",
    "    #aug = k.layers.RandomFlip(mode='horizontal')(aug)\n",
    "    aug = RandomCrop(32, 32)(aug)\n",
    "    \n",
    "    layer1 = k.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform',\n",
    "        kernel_regularizer=k.regularizers.l2(wdecay), padding='same')(aug)\n",
    "    layer1 = k.layers.BatchNormalization()(layer1)\n",
    "    \n",
    "    #FIRST STACK\n",
    "    x = k.layers.Conv2D(64, (1, 1), activation='relu', kernel_initializer='he_uniform',\n",
    "        kernel_regularizer=k.regularizers.l2(wdecay), padding='same')(layer1)\n",
    "    x = k.layers.BatchNormalization()(x)\n",
    "    x = k.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform',\n",
    "        kernel_regularizer=k.regularizers.l2(wdecay), padding='same')(x)\n",
    "    x = k.layers.BatchNormalization()(x)\n",
    "    x = k.layers.Conv2D(256, (1, 1), kernel_initializer='he_uniform',\n",
    "        kernel_regularizer=k.regularizers.l2(wdecay), padding='same')(x)\n",
    "    x = k.layers.BatchNormalization()(x)\n",
    "    res = k.layers.Conv2D(256, (1, 1), kernel_initializer='he_uniform',\n",
    "        kernel_regularizer=k.regularizers.l2(wdecay), padding='same')(layer1)\n",
    "    res = k.layers.Activation(k.activations.relu)(k.layers.Add()([res, x]))\n",
    "    x = k.layers.Conv2D(64, (1, 1), activation='relu', kernel_initializer='he_uniform',\n",
    "        kernel_regularizer=k.regularizers.l2(wdecay), padding='same')(res)\n",
    "    x = k.layers.BatchNormalization()(x)\n",
    "    x = k.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform',\n",
    "        kernel_regularizer=k.regularizers.l2(wdecay), padding='same')(x)\n",
    "    x = k.layers.BatchNormalization()(x)\n",
    "    x = k.layers.Conv2D(256, (1, 1), kernel_initializer='he_uniform',\n",
    "        kernel_regularizer=k.regularizers.l2(wdecay), padding='same')(x)\n",
    "    x = k.layers.BatchNormalization()(x)\n",
    "    res = k.layers.Activation(k.activations.relu)(k.layers.Add()([res, x]))\n",
    "    x = k.layers.Conv2D(64, (1, 1), activation='relu', kernel_initializer='he_uniform',\n",
    "        kernel_regularizer=k.regularizers.l2(wdecay), padding='same')(res)\n",
    "    x = k.layers.BatchNormalization()(x)\n",
    "    x = k.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform',\n",
    "        kernel_regularizer=k.regularizers.l2(wdecay), padding='same')(x)\n",
    "    x = k.layers.BatchNormalization()(x)\n",
    "    x = k.layers.Conv2D(256, (1, 1), kernel_initializer='he_uniform',\n",
    "        kernel_regularizer=k.regularizers.l2(wdecay), padding='same')(x)\n",
    "    x = k.layers.BatchNormalization()(x)\n",
    "    res = k.layers.Activation(k.activations.relu)(k.layers.Add()([res, x]))\n",
    "    \n",
    "    #SECOND STACK\n",
    "    x = k.layers.Conv2D(128, (1, 1), strides=(2, 2), activation='relu', kernel_initializer='he_uniform',\n",
    "        kernel_regularizer=k.regularizers.l2(wdecay), padding='same')(res)\n",
    "    x = k.layers.BatchNormalization()(x)\n",
    "    x = k.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform',\n",
    "        kernel_regularizer=k.regularizers.l2(wdecay), padding='same')(x)\n",
    "    x = k.layers.BatchNormalization()(x)\n",
    "    x = k.layers.Conv2D(512, (1, 1), kernel_initializer='he_uniform',\n",
    "        kernel_regularizer=k.regularizers.l2(wdecay), padding='same')(x)\n",
    "    x = k.layers.BatchNormalization()(x)\n",
    "    res = k.layers.Conv2D(512, (1, 1), strides=(2, 2), kernel_initializer='he_uniform',\n",
    "        kernel_regularizer=k.regularizers.l2(wdecay), padding='same')(res)\n",
    "    res = k.layers.Activation(k.activations.relu)(k.layers.Add()([res, x]))\n",
    "    x = k.layers.Conv2D(128, (1, 1), activation='relu', kernel_initializer='he_uniform',\n",
    "        kernel_regularizer=k.regularizers.l2(wdecay), padding='same')(res)\n",
    "    x = k.layers.BatchNormalization()(x)\n",
    "    x = k.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform',\n",
    "        kernel_regularizer=k.regularizers.l2(wdecay), padding='same')(x)\n",
    "    x = k.layers.BatchNormalization()(x)\n",
    "    x = k.layers.Conv2D(512, (1, 1), kernel_initializer='he_uniform',\n",
    "        kernel_regularizer=k.regularizers.l2(wdecay), padding='same')(x)\n",
    "    x = k.layers.BatchNormalization()(x)\n",
    "    res = k.layers.Activation(k.activations.relu)(k.layers.Add()([res, x]))\n",
    "    x = k.layers.Conv2D(128, (1, 1), activation='relu', kernel_initializer='he_uniform',\n",
    "        kernel_regularizer=k.regularizers.l2(wdecay), padding='same')(res)\n",
    "    x = k.layers.BatchNormalization()(x)\n",
    "    x = k.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform',\n",
    "        kernel_regularizer=k.regularizers.l2(wdecay), padding='same')(x)\n",
    "    x = k.layers.BatchNormalization()(x)\n",
    "    x = k.layers.Conv2D(512, (1, 1), kernel_initializer='he_uniform',\n",
    "        kernel_regularizer=k.regularizers.l2(wdecay), padding='same')(x)\n",
    "    x = k.layers.BatchNormalization()(x)\n",
    "    res = k.layers.Activation(k.activations.relu)(k.layers.Add()([res, x]))\n",
    "    \n",
    "    #THIRD STACK\n",
    "    x = k.layers.Conv2D(256, (1, 1), strides=(2, 2), activation='relu', kernel_initializer='he_uniform',\n",
    "        kernel_regularizer=k.regularizers.l2(wdecay), padding='same')(res)\n",
    "    x = k.layers.BatchNormalization()(x)\n",
    "    x = k.layers.Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_uniform',\n",
    "        kernel_regularizer=k.regularizers.l2(wdecay), padding='same')(x)\n",
    "    x = k.layers.BatchNormalization()(x)\n",
    "    x = k.layers.Conv2D(1024, (1, 1), kernel_initializer='he_uniform',\n",
    "        kernel_regularizer=k.regularizers.l2(wdecay), padding='same')(x)\n",
    "    x = k.layers.BatchNormalization()(x)\n",
    "    res = k.layers.Conv2D(1024, (1, 1), strides=(2, 2), kernel_initializer='he_uniform',\n",
    "        kernel_regularizer=k.regularizers.l2(wdecay), padding='same')(res)\n",
    "    res = k.layers.Activation(k.activations.relu)(k.layers.Add()([res, x]))\n",
    "    x = k.layers.Conv2D(256, (1, 1), activation='relu', kernel_initializer='he_uniform',\n",
    "        kernel_regularizer=k.regularizers.l2(wdecay), padding='same')(res)\n",
    "    x = k.layers.BatchNormalization()(x)\n",
    "    x = k.layers.Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_uniform',\n",
    "        kernel_regularizer=k.regularizers.l2(wdecay), padding='same')(x)\n",
    "    x = k.layers.BatchNormalization()(x)\n",
    "    x = k.layers.Conv2D(1024, (1, 1), kernel_initializer='he_uniform',\n",
    "        kernel_regularizer=k.regularizers.l2(wdecay), padding='same')(x)\n",
    "    x = k.layers.BatchNormalization()(x)\n",
    "    res = k.layers.Activation(k.activations.relu)(k.layers.Add()([res, x]))\n",
    "    x = k.layers.Conv2D(256, (1, 1), activation='relu', kernel_initializer='he_uniform',\n",
    "        kernel_regularizer=k.regularizers.l2(wdecay), padding='same')(res)\n",
    "    x = k.layers.BatchNormalization()(x)\n",
    "    x = k.layers.Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_uniform',\n",
    "        kernel_regularizer=k.regularizers.l2(wdecay), padding='same')(x)\n",
    "    x = k.layers.BatchNormalization()(x)\n",
    "    x = k.layers.Conv2D(1024, (1, 1), kernel_initializer='he_uniform',\n",
    "        kernel_regularizer=k.regularizers.l2(wdecay), padding='same')(x)\n",
    "    x = k.layers.BatchNormalization()(x)\n",
    "    res = k.layers.Activation(k.activations.relu)(k.layers.Add()([res, x]))\n",
    "    \n",
    "    res = k.layers.GlobalAveragePooling2D()(res)\n",
    "    \n",
    "    outputs = k.layers.Dense(10, activation='softmax')(res)\n",
    "    \n",
    "    return k.Model(inputs=inputs, outputs=outputs, name='ResNext_29')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"ResNext_29\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_9 (InputLayer)           [(None, 32, 32, 3)]  0           []                               \n",
      "                                                                                                  \n",
      " zero_padding2d_8 (ZeroPadding2  (None, 32, 32, 3)   0           ['input_9[0][0]']                \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " random_crop_8 (RandomCrop)     (None, 32, 32, 3)    0           ['zero_padding2d_8[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_168 (Conv2D)            (None, 32, 32, 64)   1792        ['random_crop_8[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_152 (Batch  (None, 32, 32, 64)  256         ['conv2d_168[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_169 (Conv2D)            (None, 32, 32, 64)   4160        ['batch_normalization_152[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_153 (Batch  (None, 32, 32, 64)  256         ['conv2d_169[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_170 (Conv2D)            (None, 32, 32, 64)   36928       ['batch_normalization_153[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_154 (Batch  (None, 32, 32, 64)  256         ['conv2d_170[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_171 (Conv2D)            (None, 32, 32, 256)  16640       ['batch_normalization_154[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_172 (Conv2D)            (None, 32, 32, 256)  16640       ['batch_normalization_152[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_155 (Batch  (None, 32, 32, 256)  1024       ['conv2d_171[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " add_72 (Add)                   (None, 32, 32, 256)  0           ['conv2d_172[0][0]',             \n",
      "                                                                  'batch_normalization_155[0][0]']\n",
      "                                                                                                  \n",
      " activation_224 (Activation)    (None, 32, 32, 256)  0           ['add_72[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_173 (Conv2D)            (None, 32, 32, 64)   16448       ['activation_224[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_156 (Batch  (None, 32, 32, 64)  256         ['conv2d_173[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_174 (Conv2D)            (None, 32, 32, 64)   36928       ['batch_normalization_156[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_157 (Batch  (None, 32, 32, 64)  256         ['conv2d_174[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_175 (Conv2D)            (None, 32, 32, 256)  16640       ['batch_normalization_157[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_158 (Batch  (None, 32, 32, 256)  1024       ['conv2d_175[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " add_73 (Add)                   (None, 32, 32, 256)  0           ['activation_224[0][0]',         \n",
      "                                                                  'batch_normalization_158[0][0]']\n",
      "                                                                                                  \n",
      " activation_225 (Activation)    (None, 32, 32, 256)  0           ['add_73[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_176 (Conv2D)            (None, 32, 32, 64)   16448       ['activation_225[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_159 (Batch  (None, 32, 32, 64)  256         ['conv2d_176[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_177 (Conv2D)            (None, 32, 32, 64)   36928       ['batch_normalization_159[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_160 (Batch  (None, 32, 32, 64)  256         ['conv2d_177[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_178 (Conv2D)            (None, 32, 32, 256)  16640       ['batch_normalization_160[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_161 (Batch  (None, 32, 32, 256)  1024       ['conv2d_178[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " add_74 (Add)                   (None, 32, 32, 256)  0           ['activation_225[0][0]',         \n",
      "                                                                  'batch_normalization_161[0][0]']\n",
      "                                                                                                  \n",
      " activation_226 (Activation)    (None, 32, 32, 256)  0           ['add_74[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_179 (Conv2D)            (None, 16, 16, 128)  32896       ['activation_226[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_162 (Batch  (None, 16, 16, 128)  512        ['conv2d_179[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_180 (Conv2D)            (None, 16, 16, 128)  147584      ['batch_normalization_162[0][0]']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " batch_normalization_163 (Batch  (None, 16, 16, 128)  512        ['conv2d_180[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_181 (Conv2D)            (None, 16, 16, 512)  66048       ['batch_normalization_163[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_182 (Conv2D)            (None, 16, 16, 512)  131584      ['activation_226[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_164 (Batch  (None, 16, 16, 512)  2048       ['conv2d_181[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " add_75 (Add)                   (None, 16, 16, 512)  0           ['conv2d_182[0][0]',             \n",
      "                                                                  'batch_normalization_164[0][0]']\n",
      "                                                                                                  \n",
      " activation_227 (Activation)    (None, 16, 16, 512)  0           ['add_75[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_183 (Conv2D)            (None, 16, 16, 128)  65664       ['activation_227[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_165 (Batch  (None, 16, 16, 128)  512        ['conv2d_183[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_184 (Conv2D)            (None, 16, 16, 128)  147584      ['batch_normalization_165[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_166 (Batch  (None, 16, 16, 128)  512        ['conv2d_184[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_185 (Conv2D)            (None, 16, 16, 512)  66048       ['batch_normalization_166[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_167 (Batch  (None, 16, 16, 512)  2048       ['conv2d_185[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " add_76 (Add)                   (None, 16, 16, 512)  0           ['activation_227[0][0]',         \n",
      "                                                                  'batch_normalization_167[0][0]']\n",
      "                                                                                                  \n",
      " activation_228 (Activation)    (None, 16, 16, 512)  0           ['add_76[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_186 (Conv2D)            (None, 16, 16, 128)  65664       ['activation_228[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_168 (Batch  (None, 16, 16, 128)  512        ['conv2d_186[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_187 (Conv2D)            (None, 16, 16, 128)  147584      ['batch_normalization_168[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_169 (Batch  (None, 16, 16, 128)  512        ['conv2d_187[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_188 (Conv2D)            (None, 16, 16, 512)  66048       ['batch_normalization_169[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_170 (Batch  (None, 16, 16, 512)  2048       ['conv2d_188[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " add_77 (Add)                   (None, 16, 16, 512)  0           ['activation_228[0][0]',         \n",
      "                                                                  'batch_normalization_170[0][0]']\n",
      "                                                                                                  \n",
      " activation_229 (Activation)    (None, 16, 16, 512)  0           ['add_77[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_189 (Conv2D)            (None, 8, 8, 256)    131328      ['activation_229[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_171 (Batch  (None, 8, 8, 256)   1024        ['conv2d_189[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_190 (Conv2D)            (None, 8, 8, 256)    590080      ['batch_normalization_171[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_172 (Batch  (None, 8, 8, 256)   1024        ['conv2d_190[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_191 (Conv2D)            (None, 8, 8, 1024)   263168      ['batch_normalization_172[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_192 (Conv2D)            (None, 8, 8, 1024)   525312      ['activation_229[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_173 (Batch  (None, 8, 8, 1024)  4096        ['conv2d_191[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " add_78 (Add)                   (None, 8, 8, 1024)   0           ['conv2d_192[0][0]',             \n",
      "                                                                  'batch_normalization_173[0][0]']\n",
      "                                                                                                  \n",
      " activation_230 (Activation)    (None, 8, 8, 1024)   0           ['add_78[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_193 (Conv2D)            (None, 8, 8, 256)    262400      ['activation_230[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_174 (Batch  (None, 8, 8, 256)   1024        ['conv2d_193[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " conv2d_194 (Conv2D)            (None, 8, 8, 256)    590080      ['batch_normalization_174[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_175 (Batch  (None, 8, 8, 256)   1024        ['conv2d_194[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_195 (Conv2D)            (None, 8, 8, 1024)   263168      ['batch_normalization_175[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_176 (Batch  (None, 8, 8, 1024)  4096        ['conv2d_195[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " add_79 (Add)                   (None, 8, 8, 1024)   0           ['activation_230[0][0]',         \n",
      "                                                                  'batch_normalization_176[0][0]']\n",
      "                                                                                                  \n",
      " activation_231 (Activation)    (None, 8, 8, 1024)   0           ['add_79[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_196 (Conv2D)            (None, 8, 8, 256)    262400      ['activation_231[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_177 (Batch  (None, 8, 8, 256)   1024        ['conv2d_196[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_197 (Conv2D)            (None, 8, 8, 256)    590080      ['batch_normalization_177[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_178 (Batch  (None, 8, 8, 256)   1024        ['conv2d_197[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_198 (Conv2D)            (None, 8, 8, 1024)   263168      ['batch_normalization_178[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_179 (Batch  (None, 8, 8, 1024)  4096        ['conv2d_198[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " add_80 (Add)                   (None, 8, 8, 1024)   0           ['activation_231[0][0]',         \n",
      "                                                                  'batch_normalization_179[0][0]']\n",
      "                                                                                                  \n",
      " activation_232 (Activation)    (None, 8, 8, 1024)   0           ['add_80[0][0]']                 \n",
      "                                                                                                  \n",
      " global_average_pooling2d_8 (Gl  (None, 1024)        0           ['activation_232[0][0]']         \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " dense_8 (Dense)                (None, 10)           10250       ['global_average_pooling2d_8[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4,936,842\n",
      "Trainable params: 4,920,586\n",
      "Non-trainable params: 16,256\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "resnext = define_resnext()\n",
    "resnext.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_convnext(wdecay=0):\n",
    "    inputs = k.Input(shape=(32, 32, 3))\n",
    "    \n",
    "    #DATA AUGMENTATION (inactive during inference)\n",
    "    aug = ZeroPadding2D(4)(inputs)\n",
    "    #aug = k.layers.RandomFlip(mode='horizontal')(aug)\n",
    "    aug = RandomCrop(32, 32)(aug)\n",
    "    \n",
    "    layer1 = k.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform',\n",
    "        kernel_regularizer=k.regularizers.l2(wdecay), padding='same')(aug)\n",
    "    #layer1 = k.layers.BatchNormalization()(layer1)\n",
    "    #FIRST STACK\n",
    "    x = k.layers.DepthwiseConv2D((3, 3), activation='relu', kernel_initializer='he_uniform',\n",
    "        kernel_regularizer=k.regularizers.l2(wdecay), padding='same')(layer1)\n",
    "    x = k.layers.BatchNormalization()(x)\n",
    "    x = k.layers.Conv2D(256, (1, 1), activation='relu', kernel_initializer='he_uniform',\n",
    "        kernel_regularizer=k.regularizers.l2(wdecay), padding='same')(x)\n",
    "    #x = k.layers.BatchNormalization()(x)\n",
    "    x = k.layers.Conv2D(64, (1, 1), activation='relu', kernel_initializer='he_uniform',\n",
    "        kernel_regularizer=k.regularizers.l2(wdecay), padding='same')(x)\n",
    "    #x = k.layers.BatchNormalization()(x)\n",
    "    res = k.layers.Activation(k.activations.relu)(k.layers.Add()([layer1, x]))\n",
    "    x = k.layers.DepthwiseConv2D((3, 3), activation='relu', kernel_initializer='he_uniform',\n",
    "        kernel_regularizer=k.regularizers.l2(wdecay), padding='same')(res)\n",
    "    x = k.layers.BatchNormalization()(x)\n",
    "    x = k.layers.Conv2D(256, (1, 1), activation='relu', kernel_initializer='he_uniform',\n",
    "        kernel_regularizer=k.regularizers.l2(wdecay), padding='same')(x)\n",
    "    #x = k.layers.BatchNormalization()(x)\n",
    "    x = k.layers.Conv2D(64, (1, 1), activation='relu', kernel_initializer='he_uniform',\n",
    "        kernel_regularizer=k.regularizers.l2(wdecay), padding='same')(x)\n",
    "    #x = k.layers.BatchNormalization()(x)\n",
    "    res = k.layers.Activation(k.activations.relu)(k.layers.Add()([res, x]))\n",
    "    x = k.layers.DepthwiseConv2D((3, 3), activation='relu', kernel_initializer='he_uniform',\n",
    "        kernel_regularizer=k.regularizers.l2(wdecay), padding='same')(res)\n",
    "    x = k.layers.BatchNormalization()(x)\n",
    "    x = k.layers.Conv2D(256, (1, 1), activation='relu', kernel_initializer='he_uniform',\n",
    "        kernel_regularizer=k.regularizers.l2(wdecay), padding='same')(x)\n",
    "    #x = k.layers.BatchNormalization()(x)\n",
    "    x = k.layers.Conv2D(64, (1, 1), activation='relu', kernel_initializer='he_uniform',\n",
    "        kernel_regularizer=k.regularizers.l2(wdecay), padding='same')(x)\n",
    "    #x = k.layers.BatchNormalization()(x)\n",
    "    res = k.layers.Activation(k.activations.relu)(k.layers.Add()([res, x]))\n",
    "    \n",
    "    #SECOND STACK\n",
    "    x = k.layers.DepthwiseConv2D((3, 3), strides=(2, 2), activation='relu', kernel_initializer='he_uniform',\n",
    "        kernel_regularizer=k.regularizers.l2(wdecay), padding='same')(res)\n",
    "    x = k.layers.BatchNormalization()(x)\n",
    "    x = k.layers.Conv2D(512, (1, 1), activation='relu', kernel_initializer='he_uniform',\n",
    "        kernel_regularizer=k.regularizers.l2(wdecay), padding='same')(x)\n",
    "    #x = k.layers.BatchNormalization()(x)\n",
    "    x = k.layers.Conv2D(128, (1, 1), activation='relu', kernel_initializer='he_uniform',\n",
    "        kernel_regularizer=k.regularizers.l2(wdecay), padding='same')(x)\n",
    "    #x = k.layers.BatchNormalization()(x)\n",
    "    res = k.layers.Conv2D(128, (1, 1), strides=(2, 2), kernel_initializer='he_uniform',\n",
    "        kernel_regularizer=k.regularizers.l2(wdecay), padding='same')(res)\n",
    "    res = k.layers.Activation(k.activations.relu)(k.layers.Add()([res, x]))\n",
    "    x = k.layers.DepthwiseConv2D((3, 3), activation='relu', kernel_initializer='he_uniform',\n",
    "        kernel_regularizer=k.regularizers.l2(wdecay), padding='same')(res)\n",
    "    x = k.layers.BatchNormalization()(x)\n",
    "    x = k.layers.Conv2D(512, (1, 1), activation='relu', kernel_initializer='he_uniform',\n",
    "        kernel_regularizer=k.regularizers.l2(wdecay), padding='same')(x)\n",
    "    #x = k.layers.BatchNormalization()(x)\n",
    "    x = k.layers.Conv2D(128, (1, 1), activation='relu', kernel_initializer='he_uniform',\n",
    "        kernel_regularizer=k.regularizers.l2(wdecay), padding='same')(x)\n",
    "    #x = k.layers.BatchNormalization()(x)\n",
    "    res = k.layers.Activation(k.activations.relu)(k.layers.Add()([res, x]))\n",
    "    x = k.layers.DepthwiseConv2D((3, 3), activation='relu', kernel_initializer='he_uniform',\n",
    "        kernel_regularizer=k.regularizers.l2(wdecay), padding='same')(res)\n",
    "    x = k.layers.BatchNormalization()(x)\n",
    "    x = k.layers.Conv2D(512, (1, 1), activation='relu', kernel_initializer='he_uniform',\n",
    "        kernel_regularizer=k.regularizers.l2(wdecay), padding='same')(x)\n",
    "    #x = k.layers.BatchNormalization()(x)\n",
    "    x = k.layers.Conv2D(128, (1, 1), activation='relu', kernel_initializer='he_uniform',\n",
    "        kernel_regularizer=k.regularizers.l2(wdecay), padding='same')(x)\n",
    "    #x = k.layers.BatchNormalization()(x)\n",
    "    res = k.layers.Activation(k.activations.relu)(k.layers.Add()([res, x]))\n",
    "    \n",
    "    #THIRD STACK\n",
    "    x = k.layers.DepthwiseConv2D((3, 3), strides=(2, 2), activation='relu', kernel_initializer='he_uniform',\n",
    "        kernel_regularizer=k.regularizers.l2(wdecay), padding='same')(res)\n",
    "    x = k.layers.BatchNormalization()(x)\n",
    "    x = k.layers.Conv2D(1024, (1, 1), activation='relu', kernel_initializer='he_uniform',\n",
    "        kernel_regularizer=k.regularizers.l2(wdecay), padding='same')(x)\n",
    "    #x = k.layers.BatchNormalization()(x)\n",
    "    x = k.layers.Conv2D(256, (1, 1), activation='relu', kernel_initializer='he_uniform',\n",
    "        kernel_regularizer=k.regularizers.l2(wdecay), padding='same')(x)\n",
    "    #x = k.layers.BatchNormalization()(x)\n",
    "    res = k.layers.Conv2D(256, (1, 1), strides=(2, 2), kernel_initializer='he_uniform',\n",
    "        kernel_regularizer=k.regularizers.l2(wdecay), padding='same')(res)\n",
    "    res = k.layers.Activation(k.activations.relu)(k.layers.Add()([res, x]))\n",
    "    x = k.layers.DepthwiseConv2D((3, 3), activation='relu', kernel_initializer='he_uniform',\n",
    "        kernel_regularizer=k.regularizers.l2(wdecay), padding='same')(res)\n",
    "    x = k.layers.BatchNormalization()(x)\n",
    "    x = k.layers.Conv2D(1024, (1, 1), activation='relu', kernel_initializer='he_uniform',\n",
    "        kernel_regularizer=k.regularizers.l2(wdecay), padding='same')(x)\n",
    "    #x = k.layers.BatchNormalization()(x)\n",
    "    x = k.layers.Conv2D(256, (1, 1), activation='relu', kernel_initializer='he_uniform',\n",
    "        kernel_regularizer=k.regularizers.l2(wdecay), padding='same')(x)\n",
    "    #x = k.layers.BatchNormalization()(x)\n",
    "    res = k.layers.Activation(k.activations.relu)(k.layers.Add()([res, x]))\n",
    "    x = k.layers.DepthwiseConv2D((3, 3), activation='relu', kernel_initializer='he_uniform',\n",
    "        kernel_regularizer=k.regularizers.l2(wdecay), padding='same')(res)\n",
    "    x = k.layers.BatchNormalization()(x)\n",
    "    x = k.layers.Conv2D(1024, (1, 1), activation='relu', kernel_initializer='he_uniform',\n",
    "        kernel_regularizer=k.regularizers.l2(wdecay), padding='same')(x)\n",
    "    #x = k.layers.BatchNormalization()(x)\n",
    "    x = k.layers.Conv2D(256, (1, 1), activation='relu', kernel_initializer='he_uniform',\n",
    "        kernel_regularizer=k.regularizers.l2(wdecay), padding='same')(x)\n",
    "    #x = k.layers.BatchNormalization()(x)\n",
    "    res = k.layers.Activation(k.activations.relu)(k.layers.Add()([res, x]))\n",
    "    \n",
    "    res = k.layers.GlobalAveragePooling2D()(res)\n",
    "    \n",
    "    outputs = k.layers.Dense(10, activation='softmax')(res)\n",
    "    \n",
    "    return k.Model(inputs=inputs, outputs=outputs, name='ConvNext')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"ConvNext\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, 32, 32, 3)]  0           []                               \n",
      "                                                                                                  \n",
      " zero_padding2d_2 (ZeroPadding2  (None, 32, 32, 3)   0           ['input_3[0][0]']                \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " random_crop_2 (RandomCrop)     (None, 32, 32, 3)    0           ['zero_padding2d_2[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_54 (Conv2D)             (None, 32, 32, 64)   1792        ['random_crop_2[0][0]']          \n",
      "                                                                                                  \n",
      " depthwise_conv2d (DepthwiseCon  (None, 32, 32, 64)  640         ['conv2d_54[0][0]']              \n",
      " v2D)                                                                                             \n",
      "                                                                                                  \n",
      " batch_normalization_47 (BatchN  (None, 32, 32, 64)  256         ['depthwise_conv2d[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_55 (Conv2D)             (None, 32, 32, 256)  16640       ['batch_normalization_47[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_56 (Conv2D)             (None, 32, 32, 64)   16448       ['conv2d_55[0][0]']              \n",
      "                                                                                                  \n",
      " add_18 (Add)                   (None, 32, 32, 64)   0           ['conv2d_54[0][0]',              \n",
      "                                                                  'conv2d_56[0][0]']              \n",
      "                                                                                                  \n",
      " activation_18 (Activation)     (None, 32, 32, 64)   0           ['add_18[0][0]']                 \n",
      "                                                                                                  \n",
      " depthwise_conv2d_1 (DepthwiseC  (None, 32, 32, 64)  640         ['activation_18[0][0]']          \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " batch_normalization_48 (BatchN  (None, 32, 32, 64)  256         ['depthwise_conv2d_1[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_57 (Conv2D)             (None, 32, 32, 256)  16640       ['batch_normalization_48[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_58 (Conv2D)             (None, 32, 32, 64)   16448       ['conv2d_57[0][0]']              \n",
      "                                                                                                  \n",
      " add_19 (Add)                   (None, 32, 32, 64)   0           ['activation_18[0][0]',          \n",
      "                                                                  'conv2d_58[0][0]']              \n",
      "                                                                                                  \n",
      " activation_19 (Activation)     (None, 32, 32, 64)   0           ['add_19[0][0]']                 \n",
      "                                                                                                  \n",
      " depthwise_conv2d_2 (DepthwiseC  (None, 32, 32, 64)  640         ['activation_19[0][0]']          \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " batch_normalization_49 (BatchN  (None, 32, 32, 64)  256         ['depthwise_conv2d_2[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_59 (Conv2D)             (None, 32, 32, 256)  16640       ['batch_normalization_49[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_60 (Conv2D)             (None, 32, 32, 64)   16448       ['conv2d_59[0][0]']              \n",
      "                                                                                                  \n",
      " add_20 (Add)                   (None, 32, 32, 64)   0           ['activation_19[0][0]',          \n",
      "                                                                  'conv2d_60[0][0]']              \n",
      "                                                                                                  \n",
      " activation_20 (Activation)     (None, 32, 32, 64)   0           ['add_20[0][0]']                 \n",
      "                                                                                                  \n",
      " depthwise_conv2d_3 (DepthwiseC  (None, 16, 16, 64)  640         ['activation_20[0][0]']          \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " batch_normalization_50 (BatchN  (None, 16, 16, 64)  256         ['depthwise_conv2d_3[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_61 (Conv2D)             (None, 16, 16, 512)  33280       ['batch_normalization_50[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_63 (Conv2D)             (None, 16, 16, 128)  8320        ['activation_20[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_62 (Conv2D)             (None, 16, 16, 128)  65664       ['conv2d_61[0][0]']              \n",
      "                                                                                                  \n",
      " add_21 (Add)                   (None, 16, 16, 128)  0           ['conv2d_63[0][0]',              \n",
      "                                                                  'conv2d_62[0][0]']              \n",
      "                                                                                                  \n",
      " activation_21 (Activation)     (None, 16, 16, 128)  0           ['add_21[0][0]']                 \n",
      "                                                                                                  \n",
      " depthwise_conv2d_4 (DepthwiseC  (None, 16, 16, 128)  1280       ['activation_21[0][0]']          \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " batch_normalization_51 (BatchN  (None, 16, 16, 128)  512        ['depthwise_conv2d_4[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_64 (Conv2D)             (None, 16, 16, 512)  66048       ['batch_normalization_51[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_65 (Conv2D)             (None, 16, 16, 128)  65664       ['conv2d_64[0][0]']              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " add_22 (Add)                   (None, 16, 16, 128)  0           ['activation_21[0][0]',          \n",
      "                                                                  'conv2d_65[0][0]']              \n",
      "                                                                                                  \n",
      " activation_22 (Activation)     (None, 16, 16, 128)  0           ['add_22[0][0]']                 \n",
      "                                                                                                  \n",
      " depthwise_conv2d_5 (DepthwiseC  (None, 16, 16, 128)  1280       ['activation_22[0][0]']          \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " batch_normalization_52 (BatchN  (None, 16, 16, 128)  512        ['depthwise_conv2d_5[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_66 (Conv2D)             (None, 16, 16, 512)  66048       ['batch_normalization_52[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_67 (Conv2D)             (None, 16, 16, 128)  65664       ['conv2d_66[0][0]']              \n",
      "                                                                                                  \n",
      " add_23 (Add)                   (None, 16, 16, 128)  0           ['activation_22[0][0]',          \n",
      "                                                                  'conv2d_67[0][0]']              \n",
      "                                                                                                  \n",
      " activation_23 (Activation)     (None, 16, 16, 128)  0           ['add_23[0][0]']                 \n",
      "                                                                                                  \n",
      " depthwise_conv2d_6 (DepthwiseC  (None, 8, 8, 128)   1280        ['activation_23[0][0]']          \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " batch_normalization_53 (BatchN  (None, 8, 8, 128)   512         ['depthwise_conv2d_6[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_68 (Conv2D)             (None, 8, 8, 1024)   132096      ['batch_normalization_53[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_70 (Conv2D)             (None, 8, 8, 256)    33024       ['activation_23[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_69 (Conv2D)             (None, 8, 8, 256)    262400      ['conv2d_68[0][0]']              \n",
      "                                                                                                  \n",
      " add_24 (Add)                   (None, 8, 8, 256)    0           ['conv2d_70[0][0]',              \n",
      "                                                                  'conv2d_69[0][0]']              \n",
      "                                                                                                  \n",
      " activation_24 (Activation)     (None, 8, 8, 256)    0           ['add_24[0][0]']                 \n",
      "                                                                                                  \n",
      " depthwise_conv2d_7 (DepthwiseC  (None, 8, 8, 256)   2560        ['activation_24[0][0]']          \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " batch_normalization_54 (BatchN  (None, 8, 8, 256)   1024        ['depthwise_conv2d_7[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_71 (Conv2D)             (None, 8, 8, 1024)   263168      ['batch_normalization_54[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_72 (Conv2D)             (None, 8, 8, 256)    262400      ['conv2d_71[0][0]']              \n",
      "                                                                                                  \n",
      " add_25 (Add)                   (None, 8, 8, 256)    0           ['activation_24[0][0]',          \n",
      "                                                                  'conv2d_72[0][0]']              \n",
      "                                                                                                  \n",
      " activation_25 (Activation)     (None, 8, 8, 256)    0           ['add_25[0][0]']                 \n",
      "                                                                                                  \n",
      " depthwise_conv2d_8 (DepthwiseC  (None, 8, 8, 256)   2560        ['activation_25[0][0]']          \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " batch_normalization_55 (BatchN  (None, 8, 8, 256)   1024        ['depthwise_conv2d_8[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_73 (Conv2D)             (None, 8, 8, 1024)   263168      ['batch_normalization_55[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_74 (Conv2D)             (None, 8, 8, 256)    262400      ['conv2d_73[0][0]']              \n",
      "                                                                                                  \n",
      " add_26 (Add)                   (None, 8, 8, 256)    0           ['activation_25[0][0]',          \n",
      "                                                                  'conv2d_74[0][0]']              \n",
      "                                                                                                  \n",
      " activation_26 (Activation)     (None, 8, 8, 256)    0           ['add_26[0][0]']                 \n",
      "                                                                                                  \n",
      " global_average_pooling2d_2 (Gl  (None, 256)         0           ['activation_26[0][0]']          \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 10)           2570        ['global_average_pooling2d_2[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,969,098\n",
      "Trainable params: 1,966,794\n",
      "Non-trainable params: 2,304\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "convnext = define_convnext()\n",
    "convnext.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet_scheduler(epoch, lr):\n",
    "    #if epoch == 75:\n",
    "    #    lr *= 0.2\n",
    "    #if epoch == 90:\n",
    "    #    lr *= 0.1\n",
    "    #if epoch == 100:\n",
    "    #    lr *= 0.1\n",
    "    #if epoch == 135:\n",
    "    #    lr *= 0.1\n",
    "    #if epoch == 150:\n",
    "    #    lr *= 0.1\n",
    "    #if epoch == 150:\n",
    "    #    lr *= 0.2\n",
    "    #if epoch == 175:\n",
    "    #    lr *= 0.5\n",
    "    #if epoch == 225:\n",
    "    #    lr *= 0.1\n",
    "    if epoch != 0 and epoch % 5 == 0:\n",
    "    #   return lr * 0.87\n",
    "        return lr * 0.95\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet_restart(epoch, lr):\n",
    "  if epoch < 90:\n",
    "    eta_max = 0.1\n",
    "    eta_max = 0.1\n",
    "  elif epoch >= 90 and epoch < 135:\n",
    "    eta_max = 0.05\n",
    "    eta_min = 5e-5\n",
    "  else:\n",
    "    eta_max = 0.01\n",
    "    eta_min = 1e-5\n",
    "  epoch_period = 25\n",
    "  lr_t = eta_min + 0.5 * (eta_max - eta_min) * (1 + np.cos(np.pi * (epoch % epoch_period) / epoch_period))\n",
    "  return lr_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet_warm_up(epoch, lr):\n",
    "  eta_max = 0.05\n",
    "  eta_min = 1e-7\n",
    "  epoch_period = 180\n",
    "\n",
    "  if epoch < 20:\n",
    "    return eta_max * epoch / 20\n",
    "  else:\n",
    "    return eta_min + 0.5 * (eta_max - eta_min) * (1 + np.cos(np.pi * (epoch - 20) / epoch_period))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_pixels_mean(train, test, valid):\n",
    "    train -= train.mean()\n",
    "    test -= train.mean()\n",
    "    valid -= train.mean()\n",
    "    return train, test, valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_test(ep=180, learning_rate=0.1, wdecay=0, optimizer='SGD', run=True):\n",
    "    # load dataset\n",
    "    trainX, trainY, testX, testY = load_dataset()\n",
    "    # prepare pixel data\n",
    "    trainX, testX = prep_pixels_mean(trainX, testX)\n",
    "    # pad image\n",
    "    trainX = padding(trainX)\n",
    "    # define model\n",
    "    model = define_resnet(wdecay)\n",
    "    if optimizer == 'SGD':\n",
    "        opt = k.optimizers.SGD(learning_rate=learning_rate, momentum=0.9)\n",
    "    elif optimizer == 'AdamW':\n",
    "        opt = k.optimizers.experimental.AdamW()\n",
    "    model.compile(optimizer=opt, loss=k.losses.CategoricalCrossentropy(from_logits=False), metrics=['accuracy'])\n",
    "    if optimizer == 'SGD':\n",
    "        lr_sched = k.callbacks.LearningRateScheduler(resnet_restart)\n",
    "    if run:\n",
    "        history = model.fit(trainX, trainY, epochs=ep, batch_size=128, validation_split=0.1, verbose=0,\n",
    "            callbacks=[lr_sched, TqdmCallback(verbose=1)])\n",
    "        # evaluate model\n",
    "        _, acc = model.evaluate(testX, testY, verbose=0)\n",
    "        print('> %.3f' % (acc * 100.0))\n",
    "        # learning curves\n",
    "        summarize_diagnostics(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixup(X, Y, mixup_alpha):\n",
    "    #Beta samples\n",
    "    g1 = tf.random.gamma(shape=[X.shape[0]], alpha=mixup_alpha)\n",
    "    g2 = tf.random.gamma(shape=[X.shape[0]], alpha=mixup_alpha)\n",
    "    beta = (g1 / (g1 + g2))\n",
    "    #Mixup\n",
    "    lambdaX = tf.reshape(beta, (X.shape[0], 1, 1, 1))\n",
    "    lambdaY = tf.reshape(beta, (Y.shape[0], 1))\n",
    "    indices = tf.range(start=0, limit=X.shape[0], dtype=tf.int32)\n",
    "    shuffle = tf.random.shuffle(indices)\n",
    "    X_shuffled = tf.gather(X, shuffle)\n",
    "    Y_shuffled = tf.gather(Y, shuffle)\n",
    "    \n",
    "    mixedX = lambdaX * X + (1-lambdaX) * X_shuffled\n",
    "    mixedY = lambdaY * Y + (1-lambdaY) * Y_shuffled\n",
    "    \n",
    "    return mixedX, mixedY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cutmix(X, Y, cutmix_alpha):\n",
    "    print('Applying cutmix data augmentation...')\n",
    "    mixedX = np.zeros((X.shape[0], X.shape[1], X.shape[2], X.shape[3]))\n",
    "    mixedY = np.zeros((Y.shape[0], Y.shape[1]))\n",
    "    indices = tf.range(start=0, limit=X.shape[0], dtype=tf.int32)\n",
    "    shuffle = tf.random.shuffle(indices)\n",
    "    X_shuffled = tf.gather(X, shuffle)\n",
    "    Y_shuffled = tf.gather(Y, shuffle)\n",
    "    \n",
    "    for i in range(X.shape[0]):\n",
    "        #Beta samples\n",
    "        g1 = tf.random.gamma(shape=[1], alpha=cutmix_alpha)\n",
    "        g2 = tf.random.gamma(shape=[1], alpha=cutmix_alpha)\n",
    "        beta = (g1 / (g1 + g2))[0]\n",
    "\n",
    "        rx = tf.random.uniform((1,), minval=0, maxval=X.shape[1], dtype=tf.int32)[0]\n",
    "        ry = tf.random.uniform((1,), minval=0, maxval=X.shape[2], dtype=tf.int32)[0]\n",
    "        rw = X.shape[2] * tf.math.sqrt(1.0 - beta)\n",
    "        rh = X.shape[1] * tf.math.sqrt(1.0 - beta)\n",
    "        rw = tf.cast(rw, tf.int32)\n",
    "        rh = tf.cast(rh, tf.int32)\n",
    "        bx = tf.clip_by_value(rx - rw//2, 0, X.shape[1])\n",
    "        by = tf.clip_by_value(ry - rh//2, 0, X.shape[2])\n",
    "        rw = tf.clip_by_value(rx + rw//2, 0, X.shape[1])\n",
    "        rh = tf.clip_by_value(ry + rw//2, 0, X.shape[2])\n",
    "        rw -= bx\n",
    "        rh -= by\n",
    "        rw = rw if rw > 0 else 1\n",
    "        rh = rh if rh > 0 else 1\n",
    "        \n",
    "        image1 = np.array(X[i])\n",
    "        image2 = np.array(X_shuffled[i])\n",
    "        crop2 = tf.image.crop_to_bounding_box(image2, bx, by, rw, rh)\n",
    "        image2 = tf.image.pad_to_bounding_box(crop2, bx, by, X.shape[1], X.shape[2])\n",
    "        crop1 = tf.image.crop_to_bounding_box(image1, bx, by, rw, rh)\n",
    "        padded1 = tf.image.pad_to_bounding_box(crop1, bx, by, X.shape[1], X.shape[2])\n",
    "        image1 -= padded1\n",
    "        mixedX[i] = image1 + image2\n",
    "        \n",
    "        lbda = 1 - (rw * rh) / (X.shape[1] * X.shape[2])\n",
    "        lbda = tf.cast(lbda, tf.float32)\n",
    "        mixedY[i] = lbda * Y[i] + (1 - lbda) * Y_shuffled[i]\n",
    "    \n",
    "    print('cutmix completed.')\n",
    "    return mixedX, mixedY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_test_next(\n",
    "    ep=180, normalize=True, learning_rate=0.1, wdecay=0, smoothing=0,\n",
    "    optimizer='SGD', mixup_alpha=0, cutmix_alpha=0, run=True):\n",
    "    # load dataset\n",
    "    trainX, trainY, testX, testY = load_dataset()\n",
    "    trainX = trainX.astype('float32')\n",
    "    testX = testX.astype('float32')\n",
    "    store = []\n",
    "    store.append(np.array(trainX[0]))\n",
    "    store.append(np.array(trainX[1]))\n",
    "    store.append(np.array(trainX[2]))\n",
    "    # prepare pixel data\n",
    "\n",
    "    store.append(np.array(trainX[0]))\n",
    "    store.append(np.array(trainX[1]))\n",
    "    store.append(np.array(trainX[2]))\n",
    "\n",
    "    np.random.seed(33)\n",
    "    v_indices = np.random.choice(range(50000), size=(5000), replace=False)\n",
    "    validX = trainX[v_indices]\n",
    "    validY = trainY[v_indices]\n",
    "    trainX = np.delete(trainX, v_indices, axis=0)\n",
    "    trainY = np.delete(trainY, v_indices, axis=0)\n",
    "    \n",
    "    if normalize:\n",
    "        trainX, testX, validX = prep_pixels_mean(trainX, testX, validX)\n",
    "    else:\n",
    "        trainX /= 255.0\n",
    "        testX /= 255.0\n",
    "        validX /= 255.0\n",
    "    \n",
    "    # apply mixup (typical is 0.2)\n",
    "    if mixup_alpha > 0:\n",
    "        trainX, trainY = mixup(trainX, trainY, mixup_alpha)\n",
    "    # apply cutmix (typical is 0.2) CAUTION: takes ~20 minutes\n",
    "    if cutmix_alpha > 0:\n",
    "        trainX, trainY = cutmix(trainX, trainY, cutmix_alpha)\n",
    "    store.append(np.array(trainX[0]))\n",
    "    store.append(np.array(trainX[1]))\n",
    "    store.append(np.array(trainX[2]))\n",
    "    \n",
    "    #for i in range(9):\n",
    "    #    pyplot.subplot(330 + 1 + i)\n",
    "    #    pyplot.imshow(store[i])\n",
    "    #pyplot.show()\n",
    "\n",
    "    # define model\n",
    "    model = define_resnet(wdecay)\n",
    "    wandb.init()\n",
    "    if optimizer == 'SGD':\n",
    "        opt = k.optimizers.SGD(learning_rate=learning_rate, momentum=0.9)\n",
    "    elif optimizer == 'Adam':\n",
    "        opt = k.optimizers.Adam(learning_rate=learning_rate / 10)\n",
    "    elif optimizer == 'AdamW':\n",
    "        opt = k.optimizers.experimental.AdamW(learning_rate=learning_rate / 10)\n",
    "    model.compile(optimizer=opt,\n",
    "        loss=k.losses.CategoricalCrossentropy(from_logits=False, label_smoothing=smoothing),\n",
    "        metrics=['accuracy'])\n",
    "    lr_sched = k.callbacks.LearningRateScheduler(resnet_warm_up)\n",
    "    if run:\n",
    "        history = model.fit(trainX, trainY, epochs=ep, batch_size=128, validation_data=(validX, validY), verbose=0,\n",
    "            callbacks=[WandbMetricsLogger(), lr_sched, TqdmCallback(verbose=1)])\n",
    "        # evaluate model\n",
    "        _, acc = model.evaluate(testX, testY, verbose=0)\n",
    "        print('> %.3f' % (acc * 100.0))\n",
    "        # learning curves\n",
    "        summarize_diagnostics(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fe777bce599438eb9b24b6d6836555f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0epoch [00:00, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48a557787bab4e6db7e9cdadbf03a1c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0batch [00:00, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run_test_next(ep=180, normalize=True, learning_rate=0.05, wdecay=0.0005)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0580a8501ef34cc4a6a44d3da49cb3a5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "11a99f94ee994ba88e55bfd5a0f3b3de": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_599bd01b698543d4862179b58d602e4c",
      "placeholder": "",
      "style": "IPY_MODEL_2a69ebc3543a42cb8f3b7f13082987a7",
      "value": " 0/100 [00:00&lt;?, ?epoch/s]"
     }
    },
    "1bd71775d13142608fad67f76b16d9de": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "20b3a0c23ea64b0a8cec88b20ce2bf1c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2609cdbc139448eda64a5007281b56e9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8410a2c03a0a4e0b9bef8993b5f174d3",
      "max": 100,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d138e167ea8944ac90249a738660584a",
      "value": 0
     }
    },
    "2a69ebc3543a42cb8f3b7f13082987a7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2ddf62e07d9c4ebd8750afeed96a152b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "58c409292c9942b9bd4544ecb5391cfb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f6f7d7d552714397a52faeb9c306640f",
       "IPY_MODEL_2609cdbc139448eda64a5007281b56e9",
       "IPY_MODEL_11a99f94ee994ba88e55bfd5a0f3b3de"
      ],
      "layout": "IPY_MODEL_672038268e5640a69f4a2f78431422f1"
     }
    },
    "599bd01b698543d4862179b58d602e4c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "672038268e5640a69f4a2f78431422f1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8406c76690204186997f7a12576b39aa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2ddf62e07d9c4ebd8750afeed96a152b",
      "placeholder": "",
      "style": "IPY_MODEL_b47da83585644eac8ce5d4258415ea99",
      "value": " 0.00/781 [00:00&lt;?, ?batch/s]"
     }
    },
    "8410a2c03a0a4e0b9bef8993b5f174d3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "886051aa63b8444495709ab2e7753559": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b47da83585644eac8ce5d4258415ea99": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bd521dca2e0d4089969eef089b178f1d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d064497007a24bd5a30e1d43b471864e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d138e167ea8944ac90249a738660584a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d685f89d82d94b678857665c5f688a1b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e2e7b51f124c4cb59c8cedff07cb2060": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bd521dca2e0d4089969eef089b178f1d",
      "max": 781,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1bd71775d13142608fad67f76b16d9de",
      "value": 0
     }
    },
    "f6080fc6378b4c2082fa450cea9bbb7c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_fefeeb76dabc4e21b1f61956d02ea627",
       "IPY_MODEL_e2e7b51f124c4cb59c8cedff07cb2060",
       "IPY_MODEL_8406c76690204186997f7a12576b39aa"
      ],
      "layout": "IPY_MODEL_20b3a0c23ea64b0a8cec88b20ce2bf1c"
     }
    },
    "f6f7d7d552714397a52faeb9c306640f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d685f89d82d94b678857665c5f688a1b",
      "placeholder": "",
      "style": "IPY_MODEL_d064497007a24bd5a30e1d43b471864e",
      "value": "  0%"
     }
    },
    "fefeeb76dabc4e21b1f61956d02ea627": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0580a8501ef34cc4a6a44d3da49cb3a5",
      "placeholder": "",
      "style": "IPY_MODEL_886051aa63b8444495709ab2e7753559",
      "value": "  0%"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
